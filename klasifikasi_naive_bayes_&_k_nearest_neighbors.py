# -*- coding: utf-8 -*-
"""Klasifikasi Naive Bayes & K-Nearest Neighbors

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11C9FWtGEXHCo0HI95Gt_ZBI67ESSHFHb

Nama : Elisabeth Faren Widyaningtyas

NIM : 4101422103

Sumber data : https://www.kaggle.com/datasets/l3llff/banana/code
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

import pandas as pd

data = pd.read_csv('banana_quality.csv')

data.head()

data.tail()

"""Dataset kualitas buah pisang ini memiliki total pengamatan sebanyak 8000. Setiap baris dalam dataset mewakili satu pisang, dan kolom-kolomnya adalah atribut-atribut yang diamati pada pisang-pisang tersebut. Berikut adalah penjelasan dari setiap variabelnya:
*   Size : Ukuran pisang
*   Wight : Berat pisang
*   Sweetness : Tingkat kemanisan pisang
*   Softness : Tingkat kelembutan pisang
*   HarvestTime : Waktu untuk panen
*   Ripeness : Tingkat kematangan pisang
*   Acidity : Kesamaan pisang
*   Quality : Variabel target atau label yang menunjukkan apakah pisang baik atau buruk. Label bernilai 1 untuk pisang yang baik dan 0 untuk pisang yang buruk.

Dataset ini memberikan informasi penting tentang karakteristik fisik buah pisang dan dapat digunakan untuk memprediksi atau menganalisis faktor-faktor yang mempengaruhi kualitas pisang pada berbagai tahap kematangan.
"""

data.describe()

"""Sebelum dilakukan pemodelan, data perlu melalui tahap preprocessing guna memastikan kualitas dan kelayakan data untuk dianalisis. Proses ini bertujuan untuk meningkatkan keakuratan model dan menghindari bias yang mungkin terjadi akibat data yang belum bersih.

# **Preprocessing Data**

### **Cek Missing Value**
"""

data.info()

"""Berdasarkan output diatas, dapat disimpulkan bahwa dataset tersebut, memiliki total: 8 kolom, dengan jumlah maksimal baris untuk setiap kolom sebanyak: 8000 baris. Semua kolom memiliki jumlah baris sebanyak 8000, maka tidak ada baris yang hilang (missing rows).

Untuk mempertegas bahwa tidak ada nilai yang hilang (Missing Value) di setiap kolom, dapat diperiksa sebagai berikut:
"""

data.isnull()

np.sum(data.isnull())

data.isnull().sum().sum()

"""Berdasarkan output diatas menunjukkan semua kolom bernilai 0 (tidak ada missing values), maka dapat disimpulkan bahwa dataset lengkap, tidak terdapat nilai yang hilang (missing values) pada kedelapan kolom yang tersedia, masing-masing terdiri dari 8000 baris data.

### **Cek dan Penanganan Outlier**

**Cek Oulier**

Sebelum masuk ke tahap pemodelan, penting untuk memeriksa apakah terdapat nilai pencilan (outlier) dalam dataset. Outlier dapat memengaruhi akurasi model, terutama pada algoritma seperti Naive Bayes dan K-Nearest Neighbors. Oleh karena itu, deteksi dan penanganan outlier dilakukan sebagai bagian dari proses pembersihan data agar model yang dibangun lebih optimal.
Cek Outlier dengan menggunakan beberapa metode:

1. Boxplot
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Kolom numerik yang ingin dicek outliernya
num_cols = ['Size', 'Weight', 'Sweetness', 'Softness',
            'HarvestTime', 'Ripeness',
            'Acidity']

# Visualisasi Boxplot
plt.figure(figsize=(15, 8))
for i, col in enumerate(num_cols, 1):
    plt.subplot(3, 4, i)
    sns.boxplot(y=data[col])
    plt.title(col)
plt.tight_layout()
plt.show()

"""2. IQR"""

def detect_outliers_iqr(data, column):
    if pd.api.types.is_numeric_dtype(data[column]):
        Q1 = data[column].quantile(0.25)  # Kuartil 1
        Q3 = data[column].quantile(0.75)  # Kuartil 3
        IQR = Q3 - Q1  # Rentang interkuartil
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        return data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    else:
        return pd.DataFrame()

# Cek jumlah outlier untuk setiap kolom numerik
for col in num_cols:
    outliers = detect_outliers_iqr(data, col)
    if not outliers.empty:
        print(f"{col}: {len(outliers)} outliers")

"""Berdasarkan output Boxplot dan IQR, terdapat outliers Size (36 outlier), Weight (3 outliers), Sweetness (178 outlier), HarvestTime (58 outlier), Ripeness (58 outlier), dan Acidity (17 outlier). Kemudian, dilakukan penanganan terhadap outlier dengan menggunakan Winsorizing (Mengganti Outlier dengan Batas IQR).

**Penanganan Outlier**
"""

def winsorize_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    data[column] = np.where(data[column] < lower_bound, lower_bound, data[column])
    data[column] = np.where(data[column] > upper_bound, upper_bound, data[column])

# Terapkan Winsorizing
for col in num_cols:
    winsorize_iqr(data, col)

#Cek boxplot kembali
num_cols = ['Size', 'Weight', 'Sweetness', 'Softness',
            'HarvestTime', 'Ripeness',
            'Acidity']

# Visualisasi Boxplot
plt.figure(figsize=(15, 8))
for i, col in enumerate(num_cols, 1):
    plt.subplot(3, 4, i)
    sns.boxplot(y=data[col])
    plt.title(col)
plt.tight_layout()
plt.show()

#IQR kembali
def detect_outliers_iqr(data, column):
    if pd.api.types.is_numeric_dtype(data[column]):
        Q1 = data[column].quantile(0.25)  # Kuartil 1
        Q3 = data[column].quantile(0.75)  # Kuartil 3
        IQR = Q3 - Q1  # Rentang interkuartil
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        return data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    else:
        return pd.DataFrame()

# Cek jumlah outlier untuk setiap kolom numerik
for col in num_cols:
    outliers = detect_outliers_iqr(data, col)
    if not outliers.empty:
        print(f"{col}: {len(outliers)} outliers")

"""Berdasarkan output boxplot, tidak terlihat adanya nilai pencilan (outlier) pada data. Selain itu, ketika dilakukan deteksi outlier menggunakan metode IQR, tidak ditemukan baris yang memenuhi kriteria sebagai outlier. Demikian dapat disimpulkan bahwa dataset ini bersih dari outlier.

### **Encoding Data Kategorik**

Dalam dataset terdapat data kategorik yakni kolom "Quality", jadi dilakukan encoding agar data dapat digunakan.
"""

#Melihat isi dalam kolom Quality
data['Quality'].unique()

"""Karena jumlah kategori hanya dua, maka encoding dilakukan menggunakan metode Label Encoding. Metode ini mengubah nilai kategori menjadi representasi numerik, di mana satu kategori diberi label 1 dan kategori lainnya diberi label 0. Dalam hal ini, kategori Good direpresentasikan sebagai 1, dan Bad sebagai 0."""

#Data sebelum encoding
print("Data Sebelum Encoding:")
print(data)

# Label Encoding
data['Quality'] = data['Quality'].map({'Good': 1, 'Bad': 0})

#Data setelah encoding
print("\nData Setelah Label Encoding:")
print(data)

"""# **Klasifikasi Data dengan Naive Bayes dan KNN**"""

count_values = data['Quality'].value_counts()
count_values

"""Jumlah perbandingan sampel data kategori 'Good' dan 'Bad' memiliki jumlah yang hampir seimbang 4006 dan 3994 sehingga dipenelitian ini tidak dilakukan perubahan lagi untuk jumlah sampel."""

# Menghitung rata-rata berdasarkan nilai 'Quality'
mean_by_quality = data.groupby('Quality').mean()

# Menampilkan rata-rata untuk setiap variabel berdasarkan nilai 'Quality'
print(mean_by_quality)

# Visualisasi. warna dibedakan berdasarkan quality apakah baik atau buruk
sns.pairplot(data, vars=['Size', 'Weight', 'Sweetness', 'Softness', 'HarvestTime', 'Ripeness', 'Acidity'], hue='Quality')

"""Visualisasi pairplot memberikan wawasan yang mendalam mengenai hubungan antara karakteristik buah dan kualitasnya. Melalui penggunaan variabel seperti 'Size', 'Weight', 'Sweetness', 'Softness', 'HarvestTime', 'Ripeness', dan 'Acidity', serta pemisahan warna berdasarkan 'Quality',dapat di identifikasi pola yang membedakan buah berkualitas baik dan buruk."""

import seaborn as sns
import pandas as pd

# Menghitung korelasi antara setiap variabel dengan 'Quality'
correlation_with_quality = data.corr()['Quality'].sort_values(ascending=False)

# Menampilkan korelasi setiap variabel dengan 'Quality'
print(correlation_with_quality)

"""Berdasarkan output, nilai korelasi antara variabel 'Quality' dengan setiap variabel lain dalam data set menunjukkan bahwa:

*   'Weight', 'Sweetness', 'HarvestTime', 'Size', dan 'Ripeness' memiliki nilai korelasi diantara rentang 0.20-0.399 dengan 'Quality'. Ini menunjukkan bahwa hubungan positif yang lemah antara kelima variabel tersebut dan kemungkinan pisang tersebut berkualitas baik (Quality=1).
*   'Acidity' dan 'Softness' memiliki i nilai korelasi yang cukup rendah dengan 'Quality' (kurang dari 0.1), yang menunjukkan hubungan yang lemah dengan kemungkinan kualitas pisang buruk (Quality=0).

**Memisahkan Variabel X dan Y**
"""

#memisahkan data menjadi variabel x dan y
x=data.drop(['Quality'], axis=1)
y=data['Quality']

"""**Membagi Data Menjadi Data Training dan Testing**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

"""**Scaling Data**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

print(x_train)
print("------------------------------------------------------------------------") # Corrected line
print(x_test)

"""## **Naive Bayes**

1. Inisialisasi Model Naive Bayes
"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()

"""2. Latih Model"""

# Fit train set Gaussian Naive Bayes
nb.fit(x_train, y_train)

"""3. Menghitung Akurasi Data Latih"""

# Compute the accuracy of train set
nb.score(x_train, y_train)

"""Untuk mengevaluasi kinerja model terhadap data latih, dilakukan perhitungan akurasi menggunakan metode `score()` dari objek model Naive Bayes. Hasil yang diperoleh menunjukkan nilai akurasi sebesar 0,884375, atau sekitar 88,44%. Nilai ini mengindikasikan bahwa model mampu mempelajari data latih dengan cukup baik, karena sebagian besar prediksi yang dihasilkan sesuai dengan label sebenarnya. Akurasi ini juga menjadi indikator awal bahwa model memiliki potensi yang baik untuk melakukan klasifikasi, meskipun perlu dikaji lebih lanjut terhadap data uji untuk memastikan bahwa model tidak mengalami overfitting.

4. Prediksi
"""

classif_name = ['NB']
y_predict = {}
y_predict['NB'] = nb.predict(x_test)

"""5. Evaluasi dan Validasi"""

from sklearn.metrics import accuracy_score
for name in classif_name:
    print('{0} accuracy = {1:.4f}'.format(name, accuracy_score(y_test, y_predict[name])))

"""Nilai akurasi 0,8931=89,31% menunjukkan bahwa model Naive Bayes sangat baik dalam mengkalsifikasikan data uji. Nilai ini sangat tinggi, menandakan bahwa KNN memang cocok untuk dataset kualitas buah pisang."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict['NB'])
print(cm)

"""Ini artinya:

True Positif (TP): 725 — Prediksi good, benar-benar good

True Negatif (TN): 778 — Prediksi bad, benar-benar bad

False Positif (FP): 102 — Prediksi good, ternyata bad

False Negatif (FN): 69 — Prediksi bad, ternyata good
"""

from sklearn.metrics import classification_report
clas = classification_report(y_test,y_predict['NB'])
print(clas)

"""Dari hasil classification report, kita bisa lihat:

* Precision untuk kelas 0 (bad) adalah 0.91, untuk kelas 1 (good) adalah 0.88.
* Recall untuk kelas 0 adalah 0.87, dan untuk kelas 1 adalah 0.91.
* F1-Score untuk kedua kelas adalah 0.89, menunjukkan keseimbangan antara precision dan recall.
* Akurasi keseluruhan: 89%.

**Visualisasi Naive Bayes**
"""

from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import ListedColormap

# Reduksi dimensi menjadi 2D
pca = PCA(n_components=2)
x_train_pca = pca.fit_transform(x_train)
x_test_pca = pca.transform(x_test)

# Latih ulang Naive Bayes pada data PCA
nb_pca = GaussianNB()
nb_pca.fit(x_train_pca, y_train)

# Buat decision boundary
h = .02
x_min, x_max = x_train_pca[:, 0].min() - 1, x_train_pca[:, 0].max() + 1
y_min, y_max = x_train_pca[:, 1].min() - 1, x_train_pca[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

Z = nb_pca.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00'])

plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, cmap=cmap_light)
plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train, cmap=cmap_bold, edgecolor='k', s=40)
plt.title("Naive Bayes (GaussianNB) dengan PCA (2D)")
plt.xlabel("PCA Komponen 1")
plt.ylabel("PCA Komponen 2")
plt.show()

"""## **KNN (K-Nearest Neighbors)**"""

Dapat dilakukan penentuan K atau jumlah tetangga terbaik sebagai berikut:

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

k_values = range(1, 21)
accuracies = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(x_train, y_train)
    y_pred = knn.predict(x_test)
    acc = accuracy_score(y_test, y_pred)
    accuracies.append(acc)

plt.figure(figsize=(8,5))
plt.plot(k_values, accuracies, marker='o')
plt.title('Akurasi vs Nilai k pada KNN')
plt.xlabel('Jumlah Tetangga (k)')
plt.ylabel('Akurasi')
plt.xticks(k_values)
plt.grid(True)
plt.show()

"""Kemudian setelah mengetahui jumlah tetangga terbaik, lanjut ke langkah berikutnya sebagai berikut:

1. Inisialisasi Model KNN (K-Nearest Neighbors)
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=8, metric='minkowski', p=2)

"""2. Latih Model"""

# Fit train set KNN (K-Nearest Neighbors
knn.fit(x_train, y_train)

"""3. Prediksi"""

classif_name = ['KNN']
y_predict = {}
y_predict['KNN'] = knn.predict(x_test)

"""4. Evaluasi dan Validasi"""

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test,y_predict['KNN'])
print('KNN accuracy :', (accuracy))

"""Nilai akurasi 0,983125 = 98,3125% menunjukkan bahwa model KKN sangat baik dalam mengkalsifikasikan data uji. Nilai ini sangat tinggi, menandakan bahwa KNN memang cocok untuk dataset kualitas buah pisang."""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict['KNN'])
print(cm)

"""Ini artinya:

True Positif (TP): 795 — Prediksi good, benar-benar good

True Negatif (TN): 778 — Prediksi bad, benar-benar bad

False Positif (FP): 11 — Prediksi good, ternyata bad

False Negatif (FN): 16 — Prediksi bad, ternyata good
"""

from sklearn.metrics import classification_report
accuracy = accuracy_score(y_test,y_predict['KNN'])
print(clas)

"""Dari hasil classification report, kita bisa lihat:

* Precision untuk kelas 0 (bad) adalah 0.91, untuk kelas 1 (good) adalah 0.88.
* Recall untuk kelas 0 adalah 0.87, dan untuk kelas 1 adalah 0.91.
* F1-Score untuk kedua kelas adalah 0.89, menunjukkan keseimbangan antara precision dan recall.
* Akurasi keseluruhan: 89%.

**Visualisasi KKN (K-Nearest Neighbors)**

Visualisasi menggunakan PCA
"""

from sklearn.decomposition import PCA
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
import numpy as np

# Reduksi fitur jadi 2D
pca = PCA(n_components=2)
x_train_pca = pca.fit_transform(x_train)
x_test_pca = pca.transform(x_test)

# Latih ulang KNN di data PCA
knn_pca = KNeighborsClassifier(n_neighbors=5)
knn_pca.fit(x_train_pca, y_train)

# Buat decision boundary
h = .02
x_min, x_max = x_train_pca[:, 0].min() - 1, x_train_pca[:, 0].max() + 1
y_min, y_max = x_train_pca[:, 1].min() - 1, x_train_pca[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))
Z = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Visualisasi
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00'])

plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, cmap=cmap_light)
plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train, cmap=cmap_bold, edgecolor='k', s=40)
plt.title("KNN (k=5) dengan PCA (2D)")
plt.xlabel("PCA Komponen 1")
plt.ylabel("PCA Komponen 2")
plt.show()

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

# 1. Load data (pakai Iris sebagai contoh)
data = load_iris()
X = data.data
y = data.target

# 2. Bagi data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 3. Standarisasi data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)
y_pred = knn.predict(X_test_scaled)

# 5. Gabungkan data untuk PCA
import numpy as np
X_all_scaled = np.vstack((X_train_scaled, X_test_scaled))
y_all_pred = np.concatenate((knn.predict(X_train_scaled), y_pred))

# 6. PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_all_scaled)

# 7. Visualisasi hasil prediksi
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_all_pred, cmap='coolwarm', edgecolor='k', s=60)
plt.title('Visualisasi Hasil Klasifikasi KNN (PCA 2D)')
plt.xlabel('Komponen Utama 1')
plt.ylabel('Komponen Utama 2')
plt.grid(True)
plt.show()

"""**Perbandingan Hasil Klasifikasi antara Naïve Bayes dan KNN**

Berdasarkan hasil dari akurasi Naive Bayes yakni sebesar 0,8931=89,31%. Sedangkan hasil dari akurasi KNN yakni sebesar 0,983125 = 98,3125%.Ini menunjukkan bahwa akurasi dari KNN (K-Nearest Neighbors) lebih tinggi daripada Naive Bayes.
"""